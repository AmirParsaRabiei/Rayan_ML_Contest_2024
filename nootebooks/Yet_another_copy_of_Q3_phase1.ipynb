{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q123oprDUPQV",
        "outputId": "b9be60e1-cace-4bda-e534-afaa67232afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "print(\"Albumentations version:\", A.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZ9CQvBVErQ",
        "outputId": "f16b6194-2f8d-4790-ff43-1eb719176b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Albumentations version: 1.4.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm albumentations.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOOz1IuNVLWu",
        "outputId": "b03a5684-e75d-4dde-ef9a-fd61bab9c2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'albumentations.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# نصب کتابخانه‌های مورد نیاز\n",
        "!pip install gdown\n",
        "!pip install tqdm\n",
        "!pip install huggingface_hub\n",
        "!pip install timm\n",
        "!pip install torchmetrics\n",
        "!pip install albumentations\n",
        "!pip install torchsummary\n",
        "!pip install scikit-learn\n",
        "!pip install pytorch-lightning\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbAfAlFlSTrp",
        "outputId": "e59fe68f-da15-4383-8551-1ede11e9c356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.1\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.15)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore>=0.0.15 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.16)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.8)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.0)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-lightning\n",
            "Successfully installed pytorch-lightning-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "import tarfile\n",
        "\n",
        "# دانلود دیتاست\n",
        "hf_hub_download(repo_id='RayanAi/inat_train_modified',\n",
        "               filename=\"inat_train_modified.tar.gz\",\n",
        "               repo_type=\"dataset\",\n",
        "               local_dir=\".\")\n",
        "\n",
        "# استخراج فایل tar.gz\n",
        "with tarfile.open(\"inat_train_modified.tar.gz\", \"r:gz\") as tar:\n",
        "    tar.extractall(path=\".\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201,
          "referenced_widgets": [
            "334a595da004408b97d686dc2e6c0eaf",
            "6d747e100f864a8786305d9846965a8d",
            "a809616b556e474984e8765a1ded1504",
            "3646a1fa885241d1ae9ec5d99fe6192e",
            "1a36e0c92c424cdaabf7d602fa023baf",
            "f25f88e2dd0248d692e1fca5b4e41ec3",
            "d4613af26e2c4839a62a33d736bbc79e",
            "dc3a13cfd34e4f1bb7c4af1307ceabdb",
            "f3623028a7e8411c9875f32ca8989618",
            "41c0e479c7e14a38914cd4594c7fba57",
            "b6163882c12b4ad087018617724869aa"
          ]
        },
        "id": "AydEIvzqSW0W",
        "outputId": "61dd9d9b-a093-4e64-ad10-ac50c1efaff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "inat_train_modified.tar.gz:   0%|          | 0.00/11.4G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "334a595da004408b97d686dc2e6c0eaf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterator\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self._count = 0\n",
        "        self.children = {}\n",
        "        self._entities = []\n",
        "\n",
        "    def add_to_node(self, path, entity, level=0):\n",
        "        if level >= len(path):\n",
        "            self._entities.append(entity)\n",
        "            return\n",
        "        part = path[level]\n",
        "        if part not in self.children:\n",
        "            self.children[part] = Node(path[:level+1])\n",
        "        self.children[part].add_to_node(path, entity, level=level+1)\n",
        "        self._count += 1\n",
        "\n",
        "    @property\n",
        "    def is_leaf(self):\n",
        "        return len(self._entities) > 0\n",
        "\n",
        "    @property\n",
        "    def count(self):\n",
        "        if self.is_leaf:\n",
        "            return len(self._entities)\n",
        "        else:\n",
        "            return self._count\n",
        "\n",
        "    @property\n",
        "    def entities(self):\n",
        "        if self.is_leaf:\n",
        "            return list((entity, self.name) for entity in self._entities)\n",
        "        else:\n",
        "            child_entities = []\n",
        "            for child in self.children.values():\n",
        "                child_entities.extend(child.entities)\n",
        "        return child_entities\n",
        "\n",
        "    def level_iterator(self, level=None):\n",
        "        if level == 0:\n",
        "            yield self\n",
        "        elif level is None and self.is_leaf:\n",
        "            yield self\n",
        "        elif self.is_leaf and level != 0:\n",
        "            raise Exception(\"Incorrect level is specified in tree.\")\n",
        "        else:\n",
        "            if level is not None:\n",
        "                level -= 1\n",
        "            for child in self.children.values():\n",
        "                for v in child.level_iterator(level):\n",
        "                    yield v\n",
        "\n",
        "    def print_node(self, level=0, max_level=None):\n",
        "        print(' ' * (level * 4) + f\"{self.name[-1]} ({self.count})\")\n",
        "        for node in self.children.values():\n",
        "            if max_level is None or level < max_level:\n",
        "                node.print_node(level + 1, max_level=max_level)\n",
        "        return\n",
        "\n",
        "class HierarchicalDataset(Dataset):\n",
        "    def __init__(self, dataset_path, level=None, transform=None, verbose=True):\n",
        "        self.tree = Node((\"Dataset\",))  # Initialize with root\n",
        "        self.level = level if level is not None else 2  # تغییر به سطح 2 بر اساس قوانین مسابقه\n",
        "        self.classes = set()\n",
        "        self.data = []\n",
        "        self.transform = transform\n",
        "\n",
        "        index = 0\n",
        "        for group_name in sorted(os.listdir(dataset_path)):\n",
        "            group_dir = os.path.join(dataset_path, group_name)\n",
        "            if not os.path.isdir(group_dir):\n",
        "                continue\n",
        "            for image_name in sorted(os.listdir(group_dir)):\n",
        "                image_path = os.path.join(group_dir, image_name)\n",
        "                group = tuple(group_name.split(\"_\")[1:])  # Assuming format like 'class_name'\n",
        "                if len(group) < self.level:\n",
        "                    continue  # Skip if group path is shorter than required level\n",
        "                group = group[:self.level]\n",
        "                self.data.append({\n",
        "                    \"image_path\": image_path,\n",
        "                    \"group\": group,\n",
        "                })\n",
        "                self.tree.add_to_node(group, index)\n",
        "                index += 1\n",
        "                self.classes.add(group)\n",
        "\n",
        "        self.classes = {group: idx for idx, group in enumerate(sorted(list(self.classes)))}\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Dataset Length: {len(self.data)}\")\n",
        "            print(\"Hierarchical Structure (up to level 2):\")\n",
        "            self.tree.print_node(max_level=2)\n",
        "            print(f\"Number of classes: {len(self.classes)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image = Image.open(sample[\"image_path\"]).convert('RGB')\n",
        "        group = sample[\"group\"][:self.level]\n",
        "        target = self.classes[group]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target\n",
        "\n",
        "    def get_group_iterator(self, level=None) -> Iterator[Node]:\n",
        "        for group in self.tree.level_iterator(level):\n",
        "            yield group\n"
      ],
      "metadata": {
        "id": "OT5WRL1YSoT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# تعریف MixUp\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if torch.cuda.is_available():\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "# تعریف CutMix\n",
        "def cutmix_data(x, y, alpha=1.0):\n",
        "    '''Returns cutmixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size, C, H, W = x.size()\n",
        "    if torch.cuda.is_available():\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    # تعریف منطقه برای برش\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    rw = int(W * np.sqrt(1 - lam))\n",
        "    rh = int(H * np.sqrt(1 - lam))\n",
        "\n",
        "    x1 = np.clip(cx - rw // 2, 0, W)\n",
        "    y1 = np.clip(cy - rh // 2, 0, H)\n",
        "    x2 = np.clip(cx + rw // 2, 0, W)\n",
        "    y2 = np.clip(cy + rh // 2, 0, H)\n",
        "\n",
        "    x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
        "    lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H))\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, y_a, y_b, lam\n",
        "\n",
        "# تعریف داده‌افزایی برای آموزش با استفاده از Albumentations\n",
        "train_transform = A.Compose([\n",
        "    # ترکیب چندین تکنیک داده‌افزایی\n",
        "    A.OneOf([\n",
        "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
        "        A.MotionBlur(blur_limit=5, p=0.3),\n",
        "    ], p=1.0),\n",
        "    A.Resize(256, 256),\n",
        "    A.RandomResizedCrop(224, 224, scale=(0.8, 1.0)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    A.Rotate(limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Normalize(mean=(0.4556, 0.4714, 0.3700), std=(0.2370, 0.2318, 0.2431)),\n",
        "    A.RandomErasing(p=0.1),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# پیش‌پردازش برای مجموعه اعتبارسنجی\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.CenterCrop(224, 224),\n",
        "    A.Normalize(mean=(0.4556, 0.4714, 0.3700), std=(0.2370, 0.2318, 0.2431)),\n",
        "    ToTensorV2()\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "NJOdtUvZSqAe",
        "outputId": "30a09bc9-9286-468b-a145-b65cd86eb879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'albumentations' has no attribute 'RandomErasing'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-84b143b6f8c6>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomBrightnessContrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4556\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4714\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2370\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2318\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2431\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomErasing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mToTensorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ])\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'albumentations' has no attribute 'RandomErasing'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from torch.amp import GradScaler  # استفاده از torch.amp\n",
        "from torchmetrics import Accuracy\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import timm  # برای مدل‌های پیشرفته‌تر\n",
        "\n",
        "def get_model(model_name, num_classes):\n",
        "    model = timm.create_model(model_name, pretrained=True)\n",
        "    in_features = model.get_classifier().in_features\n",
        "    model.classifier = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# تنظیم دستگاه\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# بارگذاری دیتاست\n",
        "dataset_path = 'train'  # مسیر دیتاست\n",
        "full_dataset = HierarchicalDataset(dataset_path=dataset_path, level=2, transform=train_transform)\n",
        "\n",
        "# محاسبه وزن‌های کلاس\n",
        "def compute_class_weights(dataset):\n",
        "    class_counts = {}\n",
        "    for _, label in dataset:\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "    total_samples = len(dataset)\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    class_weights = [total_samples / (num_classes * class_counts[i]) for i in range(num_classes)]\n",
        "    return torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "class_weights = compute_class_weights(full_dataset)\n",
        "\n",
        "# تعریف Sampler گروه‌محور\n",
        "from torch.utils.data import Sampler\n",
        "import math\n",
        "\n",
        "class GroupBalancedSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.groups = {}\n",
        "        for idx in range(len(self.dataset)):\n",
        "            _, label = self.dataset[idx]\n",
        "            if label not in self.groups:\n",
        "                self.groups[label] = []\n",
        "            self.groups[label].append(idx)\n",
        "        self.group_keys = list(self.groups.keys())\n",
        "        self.num_groups = len(self.group_keys)\n",
        "        self.samples_per_group = math.ceil(batch_size / self.num_groups)\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = []\n",
        "        for group in self.group_keys:\n",
        "            group_indices = self.groups[group]\n",
        "            if len(group_indices) < self.samples_per_group:\n",
        "                group_indices = group_indices * (self.samples_per_group // len(group_indices) + 1)\n",
        "            selected = group_indices[:self.samples_per_group]\n",
        "            indices.extend(selected)\n",
        "        np.random.shuffle(indices)\n",
        "        return iter(indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batch_size * math.ceil(len(self.dataset) / self.batch_size)\n",
        "\n",
        "# تعریف مدل‌های مختلف برای Ensemble\n",
        "model_names = ['efficientnet_b4', 'resnest50d', 'resnet50']\n",
        "models_list = [get_model(name, num_classes=len(full_dataset.classes)).to(device) for name in model_names]\n",
        "\n",
        "# تعریف Ensemble مدل‌ها\n",
        "class EnsembleModel(nn.Module):\n",
        "    def __init__(self, models):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.models = nn.ModuleList(models)\n",
        "        for model in self.models:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False  # Freeze all models\n",
        "        self.fc = nn.Linear(len(models), len(full_dataset.classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = [model(x) for model in self.models]\n",
        "        outputs = torch.stack(outputs, dim=1)  # Shape: (batch_size, num_models, num_classes)\n",
        "        outputs = outputs.mean(dim=1)  # Averaging outputs\n",
        "        return outputs\n",
        "\n",
        "ensemble_model = EnsembleModel(models_list).to(device)\n",
        "\n",
        "# تعریف Focal Loss با استفاده از وزن‌های کلاس و Label Smoothing\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2, smoothing=0.1, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.smoothing = smoothing\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Apply label smoothing\n",
        "        num_classes = inputs.size(1)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(inputs)\n",
        "            true_dist.fill_(self.smoothing / (num_classes - 1))\n",
        "            true_dist.scatter_(1, targets.data.unsqueeze(1), 1.0 - self.smoothing)\n",
        "\n",
        "        ce_loss = -true_dist * torch.log_softmax(inputs, dim=1)\n",
        "        if self.alpha is not None:\n",
        "            ce_loss = ce_loss * self.alpha.unsqueeze(0)\n",
        "\n",
        "        ce_loss = ce_loss.sum(dim=1)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "criterion = FocalLoss(alpha=class_weights, gamma=2, smoothing=0.1, reduction='mean')\n",
        "\n",
        "# تعریف بهینه‌ساز\n",
        "optimizer = optim.AdamW(ensemble_model.fc.parameters(), lr=1e-3, weight_decay=1e-5)  # Only train the final layer\n",
        "\n",
        "# تعریف تنظیم‌کننده نرخ یادگیری پیشرفته‌تر\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "\n",
        "# تعریف GradScaler برای mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# تقسیم‌بندی به مجموعه آموزشی و اعتبارسنجی با StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(full_dataset)), [label for _, label in full_dataset])):\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "    train_subset = torch.utils.data.Subset(full_dataset, train_idx)\n",
        "    val_subset = torch.utils.data.Subset(full_dataset, val_idx)\n",
        "\n",
        "    # بارگذاری داده‌ها با استفاده از GroupBalancedSampler\n",
        "    train_sampler = GroupBalancedSampler(train_subset, batch_size=64)\n",
        "    train_loader = DataLoader(train_subset, batch_size=64, sampler=train_sampler, num_workers=8, pin_memory=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    # تعریف Early Stopping\n",
        "    best_val_acc = 0.0\n",
        "    early_stopping_patience = 7\n",
        "    early_stopping_counter = 0\n",
        "\n",
        "    for epoch in range(1, 51):  # افزایش تعداد Epoch‌ها\n",
        "        print(f\"Epoch {epoch}/50\")\n",
        "\n",
        "        # آموزش\n",
        "        ensemble_model.train()\n",
        "        running_loss = 0.0\n",
        "        accuracy_metric = Accuracy(task=\"multiclass\", num_classes=len(full_dataset.classes)).to(device)\n",
        "        for inputs, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # اعمال MixUp و CutMix\n",
        "            mixed_inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=0.2)\n",
        "            mixed_inputs, targets_a, targets_b, lam = cutmix_data(mixed_inputs, targets_a, alpha=1.0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():  # استفاده از autocast برای mixed precision\n",
        "                outputs = ensemble_model(mixed_inputs)\n",
        "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step(epoch + epoch / len(train_loader))\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            accuracy_metric.update(preds, labels)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = accuracy_metric.compute().item()\n",
        "        print(f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.2f}%\")\n",
        "\n",
        "        # اعتبارسنجی\n",
        "        ensemble_model.eval()\n",
        "        running_loss = 0.0\n",
        "        accuracy_metric = Accuracy(task=\"multiclass\", num_classes=len(full_dataset.classes)).to(device)\n",
        "        group_correct = {}\n",
        "        group_total = {}\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = ensemble_model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                accuracy_metric.update(preds, labels)\n",
        "\n",
        "                # به‌روزرسانی دقت هر گروه\n",
        "                for i in range(len(labels)):\n",
        "                    label = labels[i].item()\n",
        "                    pred = preds[i].item()\n",
        "                    if label not in group_correct:\n",
        "                        group_correct[label] = 0\n",
        "                        group_total[label] = 0\n",
        "                    if pred == label:\n",
        "                        group_correct[label] += 1\n",
        "                    group_total[label] += 1\n",
        "\n",
        "        epoch_val_loss = running_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = accuracy_metric.compute().item()\n",
        "\n",
        "        # محاسبه دقت بر اساس K پایین‌ترین گروه‌ها (فرض K=10%)\n",
        "        def calculate_top_k_group_accuracy(group_correct, group_total, K=10):\n",
        "            # محاسبه دقت هر گروه\n",
        "            group_acc = {label: group_correct.get(label, 0) / group_total.get(label, 1) for label in group_total}\n",
        "            # مرتب‌سازی گروه‌ها بر اساس دقت به ترتیب صعودی\n",
        "            sorted_groups = sorted(group_acc.items(), key=lambda x: x[1])\n",
        "            # انتخاب K پایین‌ترین گروه\n",
        "            top_k_groups = sorted_groups[:K]\n",
        "            # محاسبه میانگین دقت K گروه\n",
        "            top_k_avg_acc = sum([acc for _, acc in top_k_groups]) / K\n",
        "            return top_k_avg_acc\n",
        "\n",
        "        K = max(1, int(0.1 * len(group_correct)))  # K=10%\n",
        "        top_k_avg_acc = calculate_top_k_group_accuracy(group_correct, group_total, K=K)\n",
        "\n",
        "        print(f\"Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.2f}% | Top K Acc: {top_k_avg_acc:.2f}%\")\n",
        "\n",
        "        # ذخیره چک‌پوینت بهترین مدل بر اساس Top K Accuracy\n",
        "        if top_k_avg_acc > best_val_acc:\n",
        "            best_val_acc = top_k_avg_acc\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'best_checkpoint_fold{fold + 1}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': ensemble_model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_loss': epoch_val_loss,\n",
        "                'val_acc': top_k_avg_acc,\n",
        "            }, checkpoint_path)\n",
        "            print(f\"New best model saved with Top K Acc: {best_val_acc:.2f}%\")\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "            if early_stopping_counter >= early_stopping_patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    print(f\"Best Val Top K Acc for Fold {fold + 1}: {best_val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Tt9Sb75AStag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف TTA\n",
        "def get_test_transforms():\n",
        "    return A.Compose([\n",
        "        A.Resize(256, 256),\n",
        "        A.CenterCrop(224, 224),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        A.Rotate(limit=15, p=0.5),\n",
        "        A.Normalize(mean=(0.4556, 0.4714, 0.3700), std=(0.2370, 0.2318, 0.2431)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "# تعریف دیتاست و DataLoader برای تست\n",
        "test_dataset = HierarchicalDataset(dataset_path='test', level=2, transform=get_test_transforms(), verbose=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "# تعریف مدل Ensemble\n",
        "ensemble_model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = ensemble_model(inputs)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "# ذخیره نتایج\n",
        "import pandas as pd\n",
        "\n",
        "# فرض کنید شما یک فایل نمونه‌ی Submission.csv دارید که شامل شناسه‌های تصاویر است\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['label'] = predictions\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"پیش‌بینی‌ها ذخیره شد در 'submission.csv'\")\n"
      ],
      "metadata": {
        "id": "tnB3BkW0Sx-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "334a595da004408b97d686dc2e6c0eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d747e100f864a8786305d9846965a8d",
              "IPY_MODEL_a809616b556e474984e8765a1ded1504",
              "IPY_MODEL_3646a1fa885241d1ae9ec5d99fe6192e"
            ],
            "layout": "IPY_MODEL_1a36e0c92c424cdaabf7d602fa023baf"
          }
        },
        "6d747e100f864a8786305d9846965a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25f88e2dd0248d692e1fca5b4e41ec3",
            "placeholder": "​",
            "style": "IPY_MODEL_d4613af26e2c4839a62a33d736bbc79e",
            "value": "inat_train_modified.tar.gz: 100%"
          }
        },
        "a809616b556e474984e8765a1ded1504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc3a13cfd34e4f1bb7c4af1307ceabdb",
            "max": 11446008397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3623028a7e8411c9875f32ca8989618",
            "value": 11446008397
          }
        },
        "3646a1fa885241d1ae9ec5d99fe6192e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c0e479c7e14a38914cd4594c7fba57",
            "placeholder": "​",
            "style": "IPY_MODEL_b6163882c12b4ad087018617724869aa",
            "value": " 11.4G/11.4G [04:32&lt;00:00, 42.5MB/s]"
          }
        },
        "1a36e0c92c424cdaabf7d602fa023baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f25f88e2dd0248d692e1fca5b4e41ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4613af26e2c4839a62a33d736bbc79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc3a13cfd34e4f1bb7c4af1307ceabdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3623028a7e8411c9875f32ca8989618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41c0e479c7e14a38914cd4594c7fba57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6163882c12b4ad087018617724869aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}