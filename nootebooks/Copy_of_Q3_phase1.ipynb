{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31fad491b52943ea91ef429ee4db9a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d1fe772e30c407d9df234e5a9455eb9",
              "IPY_MODEL_36ec930823474f11835e1b603f586210",
              "IPY_MODEL_dfbcf020c5ba40c8a978375a4332c816"
            ],
            "layout": "IPY_MODEL_2564f3a404cb4899aa90fb775e68bad4"
          }
        },
        "4d1fe772e30c407d9df234e5a9455eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1508d21c2f04f608ab4ba579ad9fb92",
            "placeholder": "​",
            "style": "IPY_MODEL_de196fdae78d4aa9b3e0de22410be08e",
            "value": "inat_train_modified.tar.gz: 100%"
          }
        },
        "36ec930823474f11835e1b603f586210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f900fb6b2bd4cac81e9a34ab2355b0d",
            "max": 11446008397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bad92b38a0674102beaccadfaa83ea75",
            "value": 11446008397
          }
        },
        "dfbcf020c5ba40c8a978375a4332c816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3714d5e19ade40459d0f18db6a4a77b6",
            "placeholder": "​",
            "style": "IPY_MODEL_e1ff0d2c5b0c4b20936a44de15e5321e",
            "value": " 11.4G/11.4G [04:32&lt;00:00, 42.7MB/s]"
          }
        },
        "2564f3a404cb4899aa90fb775e68bad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1508d21c2f04f608ab4ba579ad9fb92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de196fdae78d4aa9b3e0de22410be08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f900fb6b2bd4cac81e9a34ab2355b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad92b38a0674102beaccadfaa83ea75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3714d5e19ade40459d0f18db6a4a77b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ff0d2c5b0c4b20936a44de15e5321e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# نصب کتابخانه‌های مورد نیاز\n",
        "!pip install gdown\n",
        "!pip install tqdm\n",
        "!pip install huggingface_hub\n",
        "!pip install timm\n",
        "!pip install torchmetrics\n",
        "\n"
      ],
      "metadata": {
        "id": "AfWwxi46tYSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31403c00-f5e1-4bbe-98f7-43c5827d68f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.24.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (10.4.0)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n",
            "Collecting timm==0.9.7 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.5.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0.2)\n",
            "Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=8d70ef9dde3270e01b788b30dfb697d5ba8230c97ac521d339fceda4bf8a92ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=522bbb50cf503cc8d5dd9dc216feb80657ead8a0ab42a391ce9afda6a9fd53c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.11\n",
            "    Uninstalling timm-1.0.11:\n",
            "      Successfully uninstalled timm-1.0.11\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "import tarfile\n",
        "\n",
        "# دانلود دیتاست\n",
        "hf_hub_download(repo_id='RayanAi/inat_train_modified',\n",
        "               filename=\"inat_train_modified.tar.gz\",\n",
        "               repo_type=\"dataset\",\n",
        "               local_dir=\".\")\n",
        "\n",
        "# استخراج فایل tar.gz\n",
        "with tarfile.open(\"inat_train_modified.tar.gz\", \"r:gz\") as tar:\n",
        "    tar.extractall(path=\".\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "31fad491b52943ea91ef429ee4db9a9c",
            "4d1fe772e30c407d9df234e5a9455eb9",
            "36ec930823474f11835e1b603f586210",
            "dfbcf020c5ba40c8a978375a4332c816",
            "2564f3a404cb4899aa90fb775e68bad4",
            "c1508d21c2f04f608ab4ba579ad9fb92",
            "de196fdae78d4aa9b3e0de22410be08e",
            "6f900fb6b2bd4cac81e9a34ab2355b0d",
            "bad92b38a0674102beaccadfaa83ea75",
            "3714d5e19ade40459d0f18db6a4a77b6",
            "e1ff0d2c5b0c4b20936a44de15e5321e"
          ]
        },
        "id": "oE38jYvFtcM1",
        "outputId": "9594c5dc-183a-493c-eb36-c6c234a71f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "inat_train_modified.tar.gz:   0%|          | 0.00/11.4G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31fad491b52943ea91ef429ee4db9a9c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterator\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self._count = 0\n",
        "        self.children = {}\n",
        "        self._entities = []\n",
        "\n",
        "    def add_to_node(self, path, entity, level=0):\n",
        "        if level >= len(path):\n",
        "            self._entities.append(entity)\n",
        "            return\n",
        "        part = path[level]\n",
        "        if part not in self.children:\n",
        "            self.children[part] = Node(path[:level+1])\n",
        "        self.children[part].add_to_node(path, entity, level=level+1)\n",
        "        self._count += 1\n",
        "\n",
        "    @property\n",
        "    def is_leaf(self):\n",
        "        return len(self._entities) > 0\n",
        "\n",
        "    @property\n",
        "    def count(self):\n",
        "        if self.is_leaf:\n",
        "            return len(self._entities)\n",
        "        else:\n",
        "            return self._count\n",
        "\n",
        "    @property\n",
        "    def entities(self):\n",
        "        if self.is_leaf:\n",
        "            return list((entity, self.name) for entity in self._entities)\n",
        "        else:\n",
        "            child_entities = []\n",
        "            for child in self.children.values():\n",
        "                child_entities.extend(child.entities)\n",
        "        return child_entities\n",
        "\n",
        "    def level_iterator(self, level=None):\n",
        "        if level == 0:\n",
        "            yield self\n",
        "        elif level is None and self.is_leaf:\n",
        "            yield self\n",
        "        elif self.is_leaf and level != 0:\n",
        "            raise Exception(\"Incorrect level is specified in tree.\")\n",
        "        else:\n",
        "            if level is not None:\n",
        "                level -= 1\n",
        "            for child in self.children.values():\n",
        "                for v in child.level_iterator(level):\n",
        "                    yield v\n",
        "\n",
        "    def print_node(self, level=0, max_level=None):\n",
        "        print(' ' * (level * 4) + f\"{self.name[-1]} ({self.count})\")\n",
        "        for node in self.children.values():\n",
        "            if max_level is None or level < max_level:\n",
        "                node.print_node(level + 1, max_level=max_level)\n",
        "        return\n",
        "\n",
        "class HierarchicalDataset(Dataset):\n",
        "    def __init__(self, dataset_path, level=None, transform=None, verbose=True):\n",
        "        self.tree = Node((\"Dataset\",))  # Initialize with root\n",
        "        self.level = level if level is not None else 7  # Default level 7\n",
        "        self.classes = set()\n",
        "        self.data = []\n",
        "        self.transform = transform\n",
        "\n",
        "        index = 0\n",
        "        for group_name in sorted(os.listdir(dataset_path)):\n",
        "            group_dir = os.path.join(dataset_path, group_name)\n",
        "            if not os.path.isdir(group_dir):\n",
        "                continue\n",
        "            for image_name in sorted(os.listdir(group_dir)):\n",
        "                image_path = os.path.join(group_dir, image_name)\n",
        "                group = tuple(group_name.split(\"_\")[1:])  # Assuming format like 'class_name'\n",
        "                if len(group) < self.level:\n",
        "                    continue  # Skip if group path is shorter than required level\n",
        "                group = group[:self.level]\n",
        "                self.data.append({\n",
        "                    \"image_path\": image_path,\n",
        "                    \"group\": group,\n",
        "                })\n",
        "                self.tree.add_to_node(group, index)\n",
        "                index += 1\n",
        "                self.classes.add(group)\n",
        "\n",
        "        self.classes = {group: idx for idx, group in enumerate(sorted(list(self.classes)))}\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Dataset Length: {len(self.data)}\")\n",
        "            print(\"Hierarchical Structure (up to level 2):\")\n",
        "            self.tree.print_node(max_level=2)\n",
        "            print(f\"Number of classes: {len(self.classes)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image = Image.open(sample[\"image_path\"]).convert('RGB')\n",
        "        group = sample[\"group\"][:self.level]\n",
        "        target = self.classes[group]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target\n",
        "\n",
        "    def get_group_iterator(self, level=None) -> Iterator[Node]:\n",
        "        for group in self.tree.level_iterator(level):\n",
        "            yield group\n"
      ],
      "metadata": {
        "id": "xeoMBv10tdne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# افزایش داده برای مجموعه آموزشی\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),  # تبدیل به تنسور قبل از RandomErasing\n",
        "    transforms.Normalize((0.4556, 0.4714, 0.3700), (0.2370, 0.2318, 0.2431)),\n",
        "    transforms.RandomErasing(p=0.1)  # اعمال RandomErasing بعد از تبدیل به تنسور\n",
        "])\n",
        "\n",
        "# پیش‌پردازش برای مجموعه اعتبارسنجی\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4556, 0.4714, 0.3700), (0.2370, 0.2318, 0.2431))\n",
        "])\n"
      ],
      "metadata": {
        "id": "UN8VMuehtjqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from torch.amp import GradScaler  # استفاده از torch.amp\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def get_model(num_classes):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "# تنظیم دستگاه\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# بارگذاری مدل و دیتاست آموزشی\n",
        "dataset_path = 'train'  # مسیر دیتاست\n",
        "full_dataset = HierarchicalDataset(dataset_path=dataset_path, level=2, transform=train_transform)\n",
        "model = get_model(num_classes=len(full_dataset.classes)).to(device)\n",
        "\n",
        "# تنظیمات آموزش\n",
        "learning_rate = 1e-4\n",
        "batch_size = 256\n",
        "num_epochs = 30\n",
        "validation_split = 0.1\n",
        "random_seed = 42\n",
        "\n",
        "# تقسیم‌بندی به مجموعه آموزشی و اعتبارسنجی\n",
        "dataset_size = len(full_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_subset = torch.utils.data.Subset(full_dataset, train_indices)\n",
        "\n",
        "# ایجاد یک مجموعه جدید برای اعتبارسنجی بدون اعمال transforms آموزشی\n",
        "val_dataset = HierarchicalDataset(dataset_path=dataset_path, level=2, transform=val_transform, verbose=False)\n",
        "val_subset = torch.utils.data.Subset(val_dataset, val_indices)\n",
        "\n",
        "# ایجاد یک مجموعه جدید بدون اعمال transforms برای محاسبه وزن‌های کلاس\n",
        "train_dataset_no_transform = HierarchicalDataset(dataset_path=dataset_path, level=2, transform=None, verbose=False)\n",
        "train_subset_no_transform = torch.utils.data.Subset(train_dataset_no_transform, train_indices)\n",
        "\n",
        "# محاسبه وزن‌های کلاس\n",
        "def compute_class_weights(dataset):\n",
        "    class_counts = {}\n",
        "    for _, label in dataset:\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "    total_samples = len(dataset)\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    class_weights = [total_samples / (num_classes * class_counts[i]) for i in range(num_classes)]\n",
        "    return torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "class_weights = compute_class_weights(train_subset_no_transform)\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "# تعریف تابع هزینه و بهینه‌ساز\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "# تنظیم‌کننده نرخ یادگیری\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs, anneal_strategy='linear')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-1yTPQItk-0",
        "outputId": "ece07b10-f901-4bc9-ac80-2da45bce98cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Dataset Length: 99970\n",
            "Hierarchical Structure (up to level 2):\n",
            "Dataset (99970)\n",
            "    Animalia (49112)\n",
            "        Annelida (13)\n",
            "        Arthropoda (29675)\n",
            "        Chordata (18518)\n",
            "        Cnidaria (124)\n",
            "        Echinodermata (83)\n",
            "        Mollusca (699)\n",
            "    Fungi (1812)\n",
            "        Ascomycota (396)\n",
            "        Basidiomycota (1416)\n",
            "    Plantae (49046)\n",
            "        Bryophyta (133)\n",
            "        Chlorophyta (13)\n",
            "        Marchantiophyta (22)\n",
            "        Rhodophyta (22)\n",
            "        Tracheophyta (48856)\n",
            "Number of classes: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, scaler, scheduler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    # مشخص کردن task و تعداد کلاس‌ها\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():  # استفاده از autocast برای mixed precision\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # به‌روزرسانی نرخ یادگیری\n",
        "        scheduler.step()\n",
        "\n",
        "        # آمارگیری\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        accuracy.update(preds, labels)\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy.compute().item()*100)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy.compute().item()\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
        "    progress_bar = tqdm(dataloader, desc=\"Validation\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            accuracy.update(preds, labels)\n",
        "\n",
        "            progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy.compute().item()*100)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy.compute().item()\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "id": "8JFidsAHtmTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import zipfile\n",
        "from torch.amp import GradScaler\n",
        "\n",
        "# ایجاد پوشه برای چک‌پوینت‌ها\n",
        "checkpoint_dir = './checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "scaler = GradScaler()  # استفاده از GradScaler بدون پارامتر device\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler, scheduler)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # ذخیره چک‌پوینت بهترین مدل\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, 'best_checkpoint.pth')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"New best model saved with Val Acc: {best_val_acc:.2f}%\")\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# بارگذاری بهترین مدل\n",
        "best_checkpoint = torch.load(os.path.join(checkpoint_dir, 'best_checkpoint.pth'), map_location=device)\n",
        "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
        "\n",
        "# ذخیره وزن‌های نهایی مدل\n",
        "torch.save(model.state_dict(), 'resnet.pth')\n",
        "\n",
        "# ایجاد فایل ZIP برای ارسال\n",
        "with zipfile.ZipFile('submission.zip', 'w') as zipf:\n",
        "    zipf.write('resnet.pth')\n",
        "\n",
        "print(\"وزن‌های مدل به نام 'resnet.pth' ذخیره شده و در 'submission.zip' بسته‌بندی شدند.\")\n"
      ],
      "metadata": {
        "id": "im7rRR6Cto30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a84e06e-50b0-488c-b090-a42dd68e3961"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/352 [00:00<?, ?it/s]<ipython-input-61-2e7b193a5f0b>:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # استفاده از autocast برای mixed precision\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "Validation:   0%|          | 0/40 [00:00<?, ?it/s]<ipython-input-61-2e7b193a5f0b>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.3474 | Train Acc: 0.36%\n",
            "Val Loss: 1.6850 | Val Acc: 0.67%\n",
            "New best model saved with Val Acc: 0.67%\n",
            "------------------------------\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.7315 | Train Acc: 0.59%\n",
            "Val Loss: 1.1817 | Val Acc: 0.76%\n",
            "New best model saved with Val Acc: 0.76%\n",
            "------------------------------\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4352 | Train Acc: 0.66%\n",
            "Val Loss: 1.0128 | Val Acc: 0.80%\n",
            "New best model saved with Val Acc: 0.80%\n",
            "------------------------------\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3225 | Train Acc: 0.67%\n",
            "Val Loss: 1.0282 | Val Acc: 0.76%\n",
            "------------------------------\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2765 | Train Acc: 0.68%\n",
            "Val Loss: 1.0791 | Val Acc: 0.73%\n",
            "------------------------------\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2594 | Train Acc: 0.67%\n",
            "Val Loss: 0.9718 | Val Acc: 0.72%\n",
            "------------------------------\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2416 | Train Acc: 0.65%\n",
            "Val Loss: 1.2570 | Val Acc: 0.70%\n",
            "------------------------------\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2049 | Train Acc: 0.66%\n",
            "Val Loss: 1.0881 | Val Acc: 0.76%\n",
            "------------------------------\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2620 | Train Acc: 0.61%\n",
            "Val Loss: 1.1441 | Val Acc: 0.72%\n",
            "------------------------------\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2819 | Train Acc: 0.62%\n",
            "Val Loss: 1.1510 | Val Acc: 0.75%\n",
            "------------------------------\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2536 | Train Acc: 0.63%\n",
            "Val Loss: 1.3402 | Val Acc: 0.70%\n",
            "------------------------------\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1974 | Train Acc: 0.66%\n",
            "Val Loss: 1.1579 | Val Acc: 0.77%\n",
            "------------------------------\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1038 | Train Acc: 0.65%\n",
            "Val Loss: 1.3911 | Val Acc: 0.81%\n",
            "New best model saved with Val Acc: 0.81%\n",
            "------------------------------\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0605 | Train Acc: 0.66%\n",
            "Val Loss: 1.3963 | Val Acc: 0.76%\n",
            "------------------------------\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0135 | Train Acc: 0.67%\n",
            "Val Loss: 1.1749 | Val Acc: 0.80%\n",
            "------------------------------\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9032 | Train Acc: 0.70%\n",
            "Val Loss: 1.2347 | Val Acc: 0.79%\n",
            "------------------------------\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8335 | Train Acc: 0.71%\n",
            "Val Loss: 1.1019 | Val Acc: 0.81%\n",
            "------------------------------\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8323 | Train Acc: 0.70%\n",
            "Val Loss: 1.0082 | Val Acc: 0.77%\n",
            "------------------------------\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7880 | Train Acc: 0.71%\n",
            "Val Loss: 1.2312 | Val Acc: 0.83%\n",
            "New best model saved with Val Acc: 0.83%\n",
            "------------------------------\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7018 | Train Acc: 0.73%\n",
            "Val Loss: 1.3939 | Val Acc: 0.82%\n",
            "------------------------------\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7234 | Train Acc: 0.73%\n",
            "Val Loss: 1.1308 | Val Acc: 0.82%\n",
            "------------------------------\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6553 | Train Acc: 0.75%\n",
            "Val Loss: 1.2639 | Val Acc: 0.84%\n",
            "New best model saved with Val Acc: 0.84%\n",
            "------------------------------\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6472 | Train Acc: 0.75%\n",
            "Val Loss: 1.2016 | Val Acc: 0.85%\n",
            "New best model saved with Val Acc: 0.85%\n",
            "------------------------------\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6004 | Train Acc: 0.76%\n",
            "Val Loss: 1.3078 | Val Acc: 0.84%\n",
            "------------------------------\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5887 | Train Acc: 0.77%\n",
            "Val Loss: 1.3228 | Val Acc: 0.85%\n",
            "New best model saved with Val Acc: 0.85%\n",
            "------------------------------\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5528 | Train Acc: 0.78%\n",
            "Val Loss: 1.3576 | Val Acc: 0.86%\n",
            "New best model saved with Val Acc: 0.86%\n",
            "------------------------------\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5185 | Train Acc: 0.78%\n",
            "Val Loss: 1.3090 | Val Acc: 0.86%\n",
            "New best model saved with Val Acc: 0.86%\n",
            "------------------------------\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4696 | Train Acc: 0.78%\n",
            "Val Loss: 1.3866 | Val Acc: 0.86%\n",
            "------------------------------\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4723 | Train Acc: 0.79%\n",
            "Val Loss: 1.3022 | Val Acc: 0.86%\n",
            "New best model saved with Val Acc: 0.86%\n",
            "------------------------------\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4305 | Train Acc: 0.79%\n",
            "Val Loss: 1.3121 | Val Acc: 0.87%\n",
            "New best model saved with Val Acc: 0.87%\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-1a613a92e49f>:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_checkpoint = torch.load(os.path.join(checkpoint_dir, 'best_checkpoint.pth'), map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "وزن‌های مدل به نام 'resnet.pth' ذخیره شده و در 'submission.zip' بسته‌بندی شدند.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD5bCDK2NcMq",
        "outputId": "fc504d9d-bd4b-4d9b-ea45-490dd3e24a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# مسیر مدل اصلی شما\n",
        "model_path = '/content/resnet.pth'\n",
        "\n",
        "# بارگذاری مدل\n",
        "model = torch.load(model_path)\n",
        "\n",
        "# تبدیل پارامترهای مدل به نیمه‌دقت\n",
        "model.half()\n",
        "\n",
        "# ذخیره مدل با دقت نیمه\n",
        "torch.save(model, '/content/resnet_fp16.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zrMjbxL_hXPd",
        "outputId": "344a577a-6804-417e-80a2-771f5a74ee3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-f7e34b0ed487>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'collections.OrderedDict' object has no attribute 'half'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f7e34b0ed487>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# تبدیل پارامترهای مدل به نیمه‌دقت\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# ذخیره مدل با دقت نیمه\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'half'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-PJaFZ7hZv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_multiple_files(input_paths, output_zip_path, compression_level=5):\n",
        "    # Ensure compression level is within 1-9\n",
        "    compression_level = max(1, min(compression_level, 1))\n",
        "\n",
        "    # Create a zip file with the specified compression level\n",
        "    compression = zipfile.ZIP_DEFLATED\n",
        "\n",
        "    # Create the zip file\n",
        "    with zipfile.ZipFile(output_zip_path, 'w', compression) as zipf:\n",
        "        for input_path in input_paths:\n",
        "            # Check if the file or directory exists\n",
        "            if not os.path.exists(input_path):\n",
        "                print(f\"{input_path} does not exist.\")\n",
        "                continue\n",
        "\n",
        "            # If it's a directory, recursively add files\n",
        "            if os.path.isdir(input_path):\n",
        "                for root, dirs, files in os.walk(input_path):\n",
        "                    for file in files:\n",
        "                        file_full_path = os.path.join(root, file)\n",
        "                        zipf.write(file_full_path,\n",
        "                                   os.path.relpath(file_full_path,\n",
        "                                                   os.path.join(input_path, '..')))\n",
        "            # If it's a single file, add it to the zip file\n",
        "            else:\n",
        "                zipf.write(input_path, os.path.basename(input_path))\n",
        "\n",
        "    print(f\"Successfully zipped files to {output_zip_path} with compression level {compression_level}\")\n",
        "\n",
        "# Example usage:\n",
        "input_paths = ['/content/model.py', '/content/model.pth']  # List of files or directories to zip\n",
        "output_zip_path = '/content/submission1.zip'  # Path to save the output zip file\n",
        "compression_level = 5  # Compression level from 1 (fastest) to 9 (most compressed)\n",
        "zip_multiple_files(input_paths, output_zip_path, compression_level)\n"
      ],
      "metadata": {
        "id": "9dXzlyn5Ncnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf __pycache__"
      ],
      "metadata": {
        "id": "xspzOHUjdXDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf model.py /content/resnet.pth /content/submission2.zip /content/checkpoints"
      ],
      "metadata": {
        "id": "S7TJBiK9dZxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/submission.zip /content/submission5.zip"
      ],
      "metadata": {
        "id": "Rcw2C1jq7ZSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/submission5.zip /content/drive/MyDrive/ML/Rayan/Q3/submission"
      ],
      "metadata": {
        "id": "kFDCJNjwNhSY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}