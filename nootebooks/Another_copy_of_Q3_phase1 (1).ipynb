{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2122984b77024888b4fe8a8b928ef0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9660a16386bc49fbbec6cd6a4ecac9c1",
              "IPY_MODEL_fd5a5a3f164047948eb390ea11181f85",
              "IPY_MODEL_2f289a9514fe4e52bd8420ec831a66aa"
            ],
            "layout": "IPY_MODEL_1014211e1cad4ab2bb363ade4b6b953d"
          }
        },
        "9660a16386bc49fbbec6cd6a4ecac9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49594ee266ec488d9d254a61b31d5a26",
            "placeholder": "​",
            "style": "IPY_MODEL_c579fe3ce480471986acde15b6ea1575",
            "value": "inat_train_modified.tar.gz: 100%"
          }
        },
        "fd5a5a3f164047948eb390ea11181f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2ebc977cb840b3bd33bc5bb8331da9",
            "max": 11446008397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e14ec68a0d474e7ab112dd9b059e71ca",
            "value": 11446008397
          }
        },
        "2f289a9514fe4e52bd8420ec831a66aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef97a60aec4425883547430a84527ca",
            "placeholder": "​",
            "style": "IPY_MODEL_d1e48ff1684d4a6ba253c73f9f626c1b",
            "value": " 11.4G/11.4G [04:32&lt;00:00, 42.4MB/s]"
          }
        },
        "1014211e1cad4ab2bb363ade4b6b953d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49594ee266ec488d9d254a61b31d5a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c579fe3ce480471986acde15b6ea1575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d2ebc977cb840b3bd33bc5bb8331da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e14ec68a0d474e7ab112dd9b059e71ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cef97a60aec4425883547430a84527ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e48ff1684d4a6ba253c73f9f626c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# نصب کتابخانه‌های مورد نیاز\n",
        "!pip install gdown\n",
        "!pip install tqdm\n",
        "!pip install huggingface_hub\n",
        "!pip install timm\n",
        "!pip install torchmetrics\n",
        "!pip install albumentations\n",
        "!pip install torchsummary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfWwxi46tYSU",
        "outputId": "6d4a5de3-06f4-4542-ee9e-fb2a57f1c8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.15)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore>=0.0.15 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.16)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "import tarfile\n",
        "\n",
        "# دانلود دیتاست\n",
        "hf_hub_download(repo_id='RayanAi/inat_train_modified',\n",
        "               filename=\"inat_train_modified.tar.gz\",\n",
        "               repo_type=\"dataset\",\n",
        "               local_dir=\".\")\n",
        "\n",
        "# استخراج فایل tar.gz\n",
        "with tarfile.open(\"inat_train_modified.tar.gz\", \"r:gz\") as tar:\n",
        "    tar.extractall(path=\".\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "2122984b77024888b4fe8a8b928ef0ee",
            "9660a16386bc49fbbec6cd6a4ecac9c1",
            "fd5a5a3f164047948eb390ea11181f85",
            "2f289a9514fe4e52bd8420ec831a66aa",
            "1014211e1cad4ab2bb363ade4b6b953d",
            "49594ee266ec488d9d254a61b31d5a26",
            "c579fe3ce480471986acde15b6ea1575",
            "2d2ebc977cb840b3bd33bc5bb8331da9",
            "e14ec68a0d474e7ab112dd9b059e71ca",
            "cef97a60aec4425883547430a84527ca",
            "d1e48ff1684d4a6ba253c73f9f626c1b"
          ]
        },
        "id": "oE38jYvFtcM1",
        "outputId": "a2af97ea-bb61-4bc0-87ad-ece207b38631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "inat_train_modified.tar.gz:   0%|          | 0.00/11.4G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2122984b77024888b4fe8a8b928ef0ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterator\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self._count = 0\n",
        "        self.children = {}\n",
        "        self._entities = []\n",
        "\n",
        "    def add_to_node(self, path, entity, level=0):\n",
        "        if level >= len(path):\n",
        "            self._entities.append(entity)\n",
        "            return\n",
        "        part = path[level]\n",
        "        if part not in self.children:\n",
        "            self.children[part] = Node(path[:level+1])\n",
        "        self.children[part].add_to_node(path, entity, level=level+1)\n",
        "        self._count += 1\n",
        "\n",
        "    @property\n",
        "    def is_leaf(self):\n",
        "        return len(self._entities) > 0\n",
        "\n",
        "    @property\n",
        "    def count(self):\n",
        "        if self.is_leaf:\n",
        "            return len(self._entities)\n",
        "        else:\n",
        "            return self._count\n",
        "\n",
        "    @property\n",
        "    def entities(self):\n",
        "        if self.is_leaf:\n",
        "            return list((entity, self.name) for entity in self._entities)\n",
        "        else:\n",
        "            child_entities = []\n",
        "            for child in self.children.values():\n",
        "                child_entities.extend(child.entities)\n",
        "        return child_entities\n",
        "\n",
        "    def level_iterator(self, level=None):\n",
        "        if level == 0:\n",
        "            yield self\n",
        "        elif level is None and self.is_leaf:\n",
        "            yield self\n",
        "        elif self.is_leaf and level != 0:\n",
        "            raise Exception(\"Incorrect level is specified in tree.\")\n",
        "        else:\n",
        "            if level is not None:\n",
        "                level -= 1\n",
        "            for child in self.children.values():\n",
        "                for v in child.level_iterator(level):\n",
        "                    yield v\n",
        "\n",
        "    def print_node(self, level=0, max_level=None):\n",
        "        print(' ' * (level * 4) + f\"{self.name[-1]} ({self.count})\")\n",
        "        for node in self.children.values():\n",
        "            if max_level is None or level < max_level:\n",
        "                node.print_node(level + 1, max_level=max_level)\n",
        "        return\n",
        "\n",
        "class HierarchicalDataset(Dataset):\n",
        "    def __init__(self, dataset_path, level=None, transform=None, verbose=True):\n",
        "        self.tree = Node((\"Dataset\",))  # Initialize with root\n",
        "        self.level = level if level is not None else 2  # تغییر به سطح 2 بر اساس قوانین مسابقه\n",
        "        self.classes = set()\n",
        "        self.data = []\n",
        "        self.transform = transform\n",
        "\n",
        "        index = 0\n",
        "        for group_name in sorted(os.listdir(dataset_path)):\n",
        "            group_dir = os.path.join(dataset_path, group_name)\n",
        "            if not os.path.isdir(group_dir):\n",
        "                continue\n",
        "            for image_name in sorted(os.listdir(group_dir)):\n",
        "                image_path = os.path.join(group_dir, image_name)\n",
        "                group = tuple(group_name.split(\"_\")[1:])  # Assuming format like 'class_name'\n",
        "                if len(group) < self.level:\n",
        "                    continue  # Skip if group path is shorter than required level\n",
        "                group = group[:self.level]\n",
        "                self.data.append({\n",
        "                    \"image_path\": image_path,\n",
        "                    \"group\": group,\n",
        "                })\n",
        "                self.tree.add_to_node(group, index)\n",
        "                index += 1\n",
        "                self.classes.add(group)\n",
        "\n",
        "        self.classes = {group: idx for idx, group in enumerate(sorted(list(self.classes)))}\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Dataset Length: {len(self.data)}\")\n",
        "            print(\"Hierarchical Structure (up to level 2):\")\n",
        "            self.tree.print_node(max_level=2)\n",
        "            print(f\"Number of classes: {len(self.classes)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image = Image.open(sample[\"image_path\"]).convert('RGB')\n",
        "        group = sample[\"group\"][:self.level]\n",
        "        target = self.classes[group]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target\n",
        "\n",
        "    def get_group_iterator(self, level=None) -> Iterator[Node]:\n",
        "        for group in self.tree.level_iterator(level):\n",
        "            yield group\n"
      ],
      "metadata": {
        "id": "xeoMBv10tdne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# تعریف MixUp\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if torch.cuda.is_available():\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "# تعریف CutMix\n",
        "def cutmix_data(x, y, alpha=1.0):\n",
        "    '''Returns cutmixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size, C, H, W = x.size()\n",
        "    if torch.cuda.is_available():\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    # تعریف منطقه برای برش\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    rw = int(W * np.sqrt(1 - lam))\n",
        "    rh = int(H * np.sqrt(1 - lam))\n",
        "\n",
        "    x1 = np.clip(cx - rw // 2, 0, W)\n",
        "    y1 = np.clip(cy - rh // 2, 0, H)\n",
        "    x2 = np.clip(cx + rw // 2, 0, W)\n",
        "    y2 = np.clip(cy + rh // 2, 0, H)\n",
        "\n",
        "    x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
        "    lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H))\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, y_a, y_b, lam\n",
        "\n",
        "# تعریف داده‌افزایی برای آموزش\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),  # تبدیل به تنسور قبل از RandomErasing\n",
        "    transforms.Normalize((0.4556, 0.4714, 0.3700), (0.2370, 0.2318, 0.2431)),\n",
        "    transforms.RandomErasing(p=0.1)  # اعمال RandomErasing بعد از تبدیل به تنسور\n",
        "])\n",
        "\n",
        "# پیش‌پردازش برای مجموعه اعتبارسنجی\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4556, 0.4714, 0.3700), (0.2370, 0.2318, 0.2431))\n",
        "])\n"
      ],
      "metadata": {
        "id": "UN8VMuehtjqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from torch.amp import GradScaler  # استفاده از torch.amp\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def get_model(num_classes):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "# تنظیم دستگاه\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# بارگذاری مدل و دیتاست آموزشی\n",
        "dataset_path = 'train'  # مسیر دیتاست\n",
        "full_dataset = HierarchicalDataset(dataset_path=dataset_path, level=2, transform=train_transform)\n",
        "model = get_model(num_classes=len(full_dataset.classes)).to(device)\n",
        "\n",
        "# تنظیمات آموزش\n",
        "learning_rate = 1e-4\n",
        "batch_size = 256\n",
        "num_epochs = 30\n",
        "validation_split = 0.1\n",
        "random_seed = 42\n",
        "\n",
        "# تقسیم‌بندی به مجموعه آموزشی و اعتبارسنجی\n",
        "dataset_size = len(full_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_subset = torch.utils.data.Subset(full_dataset, train_indices)\n",
        "\n",
        "# ایجاد یک مجموعه جدید برای اعتبارسنجی بدون اعمال transforms آموزشی\n",
        "val_dataset = HierarchicalDataset(dataset_path=dataset_path, level=2, transform=val_transform, verbose=False)\n",
        "val_subset = torch.utils.data.Subset(val_dataset, val_indices)\n",
        "\n",
        "# ایجاد یک مجموعه جدید بدون اعمال transforms برای محاسبه وزن‌های کلاس\n",
        "train_dataset_no_transform = HierarchicalDataset(dataset_path=dataset_path, level=2, transform=None, verbose=False)\n",
        "train_subset_no_transform = torch.utils.data.Subset(train_dataset_no_transform, train_indices)\n",
        "\n",
        "# محاسبه وزن‌های کلاس\n",
        "def compute_class_weights(dataset):\n",
        "    class_counts = {}\n",
        "    for _, label in dataset:\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "    total_samples = len(dataset)\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    class_weights = [total_samples / (num_classes * class_counts[i]) for i in range(num_classes)]\n",
        "    return torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "class_weights = compute_class_weights(train_subset_no_transform)\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "# تعریف تابع هزینه و بهینه‌ساز\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "# تنظیم‌کننده نرخ یادگیری\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs, anneal_strategy='linear')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-1yTPQItk-0",
        "outputId": "0075bf0a-be2a-4bf8-cd44-c5728e9bd78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Dataset Length: 99970\n",
            "Hierarchical Structure (up to level 2):\n",
            "Dataset (99970)\n",
            "    Animalia (49112)\n",
            "        Annelida (13)\n",
            "        Arthropoda (29675)\n",
            "        Chordata (18518)\n",
            "        Cnidaria (124)\n",
            "        Echinodermata (83)\n",
            "        Mollusca (699)\n",
            "    Fungi (1812)\n",
            "        Ascomycota (396)\n",
            "        Basidiomycota (1416)\n",
            "    Plantae (49046)\n",
            "        Bryophyta (133)\n",
            "        Chlorophyta (13)\n",
            "        Marchantiophyta (22)\n",
            "        Rhodophyta (22)\n",
            "        Tracheophyta (48856)\n",
            "Number of classes: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, scaler, scheduler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    # مشخص کردن task و تعداد کلاس‌ها\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        # اعمال MixUp\n",
        "        mixed_inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=0.2)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(device_type='cuda'):  # استفاده از autocast برای mixed precision\n",
        "            outputs = model(mixed_inputs)\n",
        "            loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # به‌روزرسانی نرخ یادگیری\n",
        "        scheduler.step()\n",
        "\n",
        "        # آمارگیری\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        # برای محاسبه دقت اصلی، نیاز به استفاده از targets_a و targets_b نیست\n",
        "        accuracy.update(preds, labels)\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy.compute().item()*100)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy.compute().item()\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_classes = len(full_dataset.classes)\n",
        "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
        "    progress_bar = tqdm(dataloader, desc=\"Validation\", leave=False)\n",
        "\n",
        "    # ایجاد دیکشنری برای ذخیره دقت هر گروه\n",
        "    group_correct = {}\n",
        "    group_total = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            accuracy.update(preds, labels)\n",
        "\n",
        "            # به‌روزرسانی دقت هر گروه\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                pred = preds[i].item()\n",
        "                if label not in group_correct:\n",
        "                    group_correct[label] = 0\n",
        "                    group_total[label] = 0\n",
        "                if pred == label:\n",
        "                    group_correct[label] += 1\n",
        "                group_total[label] += 1\n",
        "\n",
        "            progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy.compute().item()*100)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy.compute().item()\n",
        "\n",
        "    # محاسبه دقت بر اساس K پایین‌ترین گروه‌ها (فرض K=10%)\n",
        "    group_acc = {label: group_correct.get(label, 0) / group_total.get(label, 1) for label in group_total}\n",
        "    sorted_groups = sorted(group_acc.items(), key=lambda x: x[1])\n",
        "    K = max(1, int(0.1 * len(group_acc)))  # K=10%\n",
        "    top_k_groups = sorted_groups[:K]\n",
        "    top_k_avg_acc = sum([acc for _, acc in top_k_groups]) / K\n",
        "\n",
        "    return epoch_loss, top_k_avg_acc\n"
      ],
      "metadata": {
        "id": "8JFidsAHtmTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import zipfile\n",
        "from torch.amp import GradScaler\n",
        "\n",
        "# ایجاد پوشه برای چک‌پوینت‌ها\n",
        "checkpoint_dir = './checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "scaler = GradScaler()  # استفاده از GradScaler بدون پارامتر device\n",
        "\n",
        "# اضافه کردن Early Stopping\n",
        "early_stopping_patience = 5\n",
        "early_stopping_counter = 0\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler, scheduler)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc (Top K): {val_acc:.2f}%\")\n",
        "\n",
        "    # ذخیره چک‌پوینت بهترین مدل\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, 'best_checkpoint.pth')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"New best model saved with Val Acc: {best_val_acc:.2f}%\")\n",
        "        early_stopping_counter = 0  # Reset counter\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# بارگذاری بهترین مدل\n",
        "best_checkpoint = torch.load(os.path.join(checkpoint_dir, 'best_checkpoint.pth'), map_location=device)\n",
        "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
        "\n",
        "# ذخیره وزن‌های نهایی مدل\n",
        "torch.save(model.state_dict(), 'resnet.pth')\n",
        "\n",
        "# ایجاد فایل ZIP برای ارسال\n",
        "with zipfile.ZipFile('submission.zip', 'w') as zipf:\n",
        "    zipf.write('resnet.pth')\n",
        "\n",
        "print(\"وزن‌های مدل به نام 'resnet.pth' ذخیره شده و در 'submission.zip' بسته‌بندی شدند.\")\n"
      ],
      "metadata": {
        "id": "im7rRR6Cto30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6fa25bf7-8ea4-446d-c70a-93cca4a5ef99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5993 | Train Acc: 0.45%\n",
            "Val Loss: 1.1964 | Val Acc (Top K): 0.00%\n",
            "------------------------------\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5619 | Train Acc: 0.44%\n",
            "Val Loss: 1.3702 | Val Acc (Top K): 0.00%\n",
            "------------------------------\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4824 | Train Acc: 0.42%\n",
            "Val Loss: 1.3586 | Val Acc (Top K): 0.00%\n",
            "------------------------------\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5788 | Train Acc: 0.44%\n",
            "Val Loss: 1.4874 | Val Acc (Top K): 0.00%\n",
            "------------------------------\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5734 | Train Acc: 0.42%\n",
            "Val Loss: 1.2419 | Val Acc (Top K): 0.00%\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r<ipython-input-21-2d791b6c0f46>:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_checkpoint = torch.load(os.path.join(checkpoint_dir, 'best_checkpoint.pth'), map_location=device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './checkpoints/best_checkpoint.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2d791b6c0f46>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# بارگذاری بهترین مدل\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mbest_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_checkpoint.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_checkpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints/best_checkpoint.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Sampler\n",
        "import math\n",
        "\n",
        "class GroupBalancedSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.groups = {}\n",
        "        for idx in range(len(self.dataset)):\n",
        "            _, label = self.dataset[idx]\n",
        "            if label not in self.groups:\n",
        "                self.groups[label] = []\n",
        "            self.groups[label].append(idx)\n",
        "        self.group_keys = list(self.groups.keys())\n",
        "        self.num_groups = len(self.group_keys)\n",
        "        self.samples_per_group = math.ceil(batch_size / self.num_groups)\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = []\n",
        "        for group in self.group_keys:\n",
        "            group_indices = self.groups[group]\n",
        "            if len(group_indices) < self.samples_per_group:\n",
        "                group_indices = group_indices * (self.samples_per_group // len(group_indices) + 1)\n",
        "            selected = group_indices[:self.samples_per_group]\n",
        "            indices.extend(selected)\n",
        "        np.random.shuffle(indices)\n",
        "        return iter(indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batch_size * math.ceil(len(self.dataset) / self.batch_size)\n"
      ],
      "metadata": {
        "id": "7BeIEPBb0RrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n"
      ],
      "metadata": {
        "id": "xoO8HlDq0V2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD5bCDK2NcMq",
        "outputId": "1bcfe63b-30aa-418d-901c-c2d4aa44b020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# مسیر مدل اصلی شما\n",
        "model_path = '/content/resnet.pth'\n",
        "\n",
        "# بارگذاری مدل\n",
        "model = torch.load(model_path)\n",
        "\n",
        "# تبدیل پارامترهای مدل به نیمه‌دقت\n",
        "model.half()\n",
        "\n",
        "# ذخیره مدل با دقت نیمه\n",
        "torch.save(model, '/content/resnet_fp16.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zrMjbxL_hXPd",
        "outputId": "344a577a-6804-417e-80a2-771f5a74ee3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-f7e34b0ed487>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'collections.OrderedDict' object has no attribute 'half'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f7e34b0ed487>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# تبدیل پارامترهای مدل به نیمه‌دقت\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# ذخیره مدل با دقت نیمه\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'half'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-PJaFZ7hZv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_multiple_files(input_paths, output_zip_path, compression_level=5):\n",
        "    # Ensure compression level is within 1-9\n",
        "    compression_level = max(1, min(compression_level, 1))\n",
        "\n",
        "    # Create a zip file with the specified compression level\n",
        "    compression = zipfile.ZIP_DEFLATED\n",
        "\n",
        "    # Create the zip file\n",
        "    with zipfile.ZipFile(output_zip_path, 'w', compression) as zipf:\n",
        "        for input_path in input_paths:\n",
        "            # Check if the file or directory exists\n",
        "            if not os.path.exists(input_path):\n",
        "                print(f\"{input_path} does not exist.\")\n",
        "                continue\n",
        "\n",
        "            # If it's a directory, recursively add files\n",
        "            if os.path.isdir(input_path):\n",
        "                for root, dirs, files in os.walk(input_path):\n",
        "                    for file in files:\n",
        "                        file_full_path = os.path.join(root, file)\n",
        "                        zipf.write(file_full_path,\n",
        "                                   os.path.relpath(file_full_path,\n",
        "                                                   os.path.join(input_path, '..')))\n",
        "            # If it's a single file, add it to the zip file\n",
        "            else:\n",
        "                zipf.write(input_path, os.path.basename(input_path))\n",
        "\n",
        "    print(f\"Successfully zipped files to {output_zip_path} with compression level {compression_level}\")\n",
        "\n",
        "# Example usage:\n",
        "input_paths = ['/content/model.py', '/content/model.pth']  # List of files or directories to zip\n",
        "output_zip_path = '/content/submission1.zip'  # Path to save the output zip file\n",
        "compression_level = 5  # Compression level from 1 (fastest) to 9 (most compressed)\n",
        "zip_multiple_files(input_paths, output_zip_path, compression_level)\n"
      ],
      "metadata": {
        "id": "9dXzlyn5Ncnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf __pycache__"
      ],
      "metadata": {
        "id": "xspzOHUjdXDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf model.py /content/resnet.pth /content/submission2.zip /content/checkpoints"
      ],
      "metadata": {
        "id": "S7TJBiK9dZxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/submission4.zip /content/drive/MyDrive/ML/Rayan/Q3/submission"
      ],
      "metadata": {
        "id": "kFDCJNjwNhSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Di6xMhDTzBMh"
      }
    }
  ]
}